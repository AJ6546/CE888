{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5880d2",
   "metadata": {},
   "source": [
    "# Seq2Seq Model\n",
    "\n",
    "Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c280aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22da88c",
   "metadata": {},
   "source": [
    "Now we load the data from json file and create a pandas data frame.\n",
    "<br> \n",
    "After deleting duplicates the size of dataset was reduced from 7000-6971.\n",
    "<br> \n",
    "I have also changed both the questions and answers to Upper Case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787db0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOW MANY HEADS OF THE DEPARTMENTS ARE OLDER TH...</td>\n",
       "      <td>SELECT COUNT(*) FROM HEAD WHERE AGE  &gt;  56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIST THE NAME, BORN STATE AND AGE OF THE HEADS...</td>\n",
       "      <td>SELECT NAME ,  BORN_STATE ,  AGE FROM HEAD ORD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIST THE CREATION YEAR, NAME AND BUDGET OF EAC...</td>\n",
       "      <td>SELECT CREATION ,  NAME ,  BUDGET_IN_BILLIONS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHAT ARE THE MAXIMUM AND MINIMUM BUDGET OF THE...</td>\n",
       "      <td>SELECT MAX(BUDGET_IN_BILLIONS) ,  MIN(BUDGET_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHAT IS THE AVERAGE NUMBER OF EMPLOYEES OF THE...</td>\n",
       "      <td>SELECT AVG(NUM_EMPLOYEES) FROM DEPARTMENT WHER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  HOW MANY HEADS OF THE DEPARTMENTS ARE OLDER TH...   \n",
       "1  LIST THE NAME, BORN STATE AND AGE OF THE HEADS...   \n",
       "2  LIST THE CREATION YEAR, NAME AND BUDGET OF EAC...   \n",
       "3  WHAT ARE THE MAXIMUM AND MINIMUM BUDGET OF THE...   \n",
       "4  WHAT IS THE AVERAGE NUMBER OF EMPLOYEES OF THE...   \n",
       "\n",
       "                                               query  \n",
       "0         SELECT COUNT(*) FROM HEAD WHERE AGE  >  56  \n",
       "1  SELECT NAME ,  BORN_STATE ,  AGE FROM HEAD ORD...  \n",
       "2  SELECT CREATION ,  NAME ,  BUDGET_IN_BILLIONS ...  \n",
       "3  SELECT MAX(BUDGET_IN_BILLIONS) ,  MIN(BUDGET_I...  \n",
       "4  SELECT AVG(NUM_EMPLOYEES) FROM DEPARTMENT WHER...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('train_spider.json')\n",
    "cols = ['question','query']\n",
    "data=df[cols]\n",
    "data=data.drop_duplicates()\n",
    "\n",
    "#Changing Everything to Uppercase\n",
    "data['query']=data['query'].str.upper()\n",
    "data['question']=data['question'].str.upper()\n",
    "data=data.drop_duplicates()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e838f2cf",
   "metadata": {},
   "source": [
    " Here we only choose instances where the query has a where condition and a Join cloause. This kind of narrows down the problem and we only focus on 1 type oof question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b79037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSetWith1JoinAndWhere():\n",
    "    df1= pd.DataFrame(columns=['query', 'question'])\n",
    "    df1=pd.concat([df1,data.loc[data['query'].str.contains('WHERE', case=False)]],ignore_index=True, sort=False)\n",
    "    df2= pd.DataFrame(columns=['query', 'question'])\n",
    "    for x in range(len(df1)):\n",
    "        if(df1.loc[x]['query'].count('JOIN')==1):\n",
    "            df2=df2.append(df1.loc[x])\n",
    "    return df2.drop_duplicates().reset_index()\n",
    "df_final=DataSetWith1JoinAndWhere()[cols].sample(n=1000,random_state=1).reset_index()\n",
    "del df_final['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c811387",
   "metadata": {},
   "source": [
    "# Train Validation Test Split\n",
    "Train 75%, Validation 15%, Test 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train Validation Test Split\n",
    "# Creating Train Validation Test Split\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df_final, target = 'query', random_state=1,\n",
    "                                                                            train_size=0.7, valid_size=0.15, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c672b",
   "metadata": {},
   "source": [
    "# Cleaning The Train Data\n",
    "<br> I have removed punctuation from Questions and changed short forms like What's to What is, So it is easier for the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee628fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Questions\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.upper()\n",
    "    text = re.sub(r\"WHATS'S\", \"WHAT IS\", text)\n",
    "    text = re.sub(r\"WHERE'S\", \"WHERE IS\", text)\n",
    "    text = re.sub(r\"\\'LL\", \" WILL\", text)\n",
    "    text = re.sub(r\"\\'VE\", \" HAVE\", text)\n",
    "    text = re.sub(r\"\\'RE\", \" ARE\", text)\n",
    "    text = re.sub(r\"\\'D\", \" WOULD\", text)\n",
    "    text = re.sub(r\"WON'T\", \"WILL NOT\", text)\n",
    "    text = re.sub(r\"CAN'T\", \"CANNOT\", text)\n",
    "    text = re.sub(r\"[\\\"#/@;:{}~|.?,]\", \"\", text)\n",
    "    for i in range(1,10):   \n",
    "        text = re.sub(r\"\\ T\"+str(i), \" \", text)\n",
    "    return text\n",
    "\n",
    "clean_questions=[]\n",
    "for question in X_train['question']:\n",
    "    clean_questions.append(clean_text(question))\n",
    "\n",
    "clean_queries=[]\n",
    "for query in y_train:\n",
    "    clean_queries.append(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b9467",
   "metadata": {},
   "source": [
    "# Tokenizing\n",
    "Tokenizing is used to change the questions and queries to vector format. I have added 2 to Vocabulary size of both Questions and Queries to represent start of sentence and end of sentence added in subsequent step.\n",
    "These vectors are saved in inputs and outputs respectively.\n",
    "I have set the Max_length to 40 and removed all the instances where the queries or questions exceed this limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ae0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing\n",
    "tokenizer_questions = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(clean_questions,\n",
    "                                                                                target_vocab_size=2**13)\n",
    "tokenizer_queries = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(clean_queries,\n",
    "                                                                                target_vocab_size=2**13)\n",
    "        \n",
    "VOCAB_SIZE_QUESTIONS = tokenizer_questions.vocab_size+2\n",
    "VOCAB_SIZE_QUERIES = tokenizer_queries.vocab_size+2\n",
    "\n",
    "inputs =[[VOCAB_SIZE_QUESTIONS-2]+tokenizer_questions.encode(sentence)+[VOCAB_SIZE_QUESTIONS-1]\n",
    "         for sentence in clean_questions]\n",
    "\n",
    "outputs =[[VOCAB_SIZE_QUERIES-2]+tokenizer_queries.encode(sentence)+[VOCAB_SIZE_QUERIES-1]\n",
    "         for sentence in clean_queries]\n",
    "\n",
    "MAX_LENGTH=40\n",
    "idx_to_remove =[count for count, sent in enumerate(inputs) if len(sent)>MAX_LENGTH]\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "    \n",
    "idx_to_remove =[count for count, sent in enumerate(outputs) if len(sent)>MAX_LENGTH]\n",
    "for idx in reversed(idx_to_remove):\n",
    "    del inputs[idx]\n",
    "    del outputs[idx]\n",
    "    \n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a044c",
   "metadata": {},
   "source": [
    "# Padding\n",
    "We use keras pad sequence to pad all the questions or queries which had length shorter than 40 to set all the inputs and outputs to have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f79078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding Inputs and Outputs\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                                  value=0,padding='post',\n",
    "                                                                  maxlen=MAX_LENGTH)\n",
    "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
    "                                                                  value=0,padding='post',\n",
    "                                                                  maxlen=MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "803ed119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size of Questions:  1796\n",
      "\n",
      "Vocab size of Queries:  2019\n"
     ]
    }
   ],
   "source": [
    "#Printing Vocab size \n",
    "print('Vocab size of Questions: ',VOCAB_SIZE_QUESTIONS)\n",
    "print('\\nVocab size of Queries: ',VOCAB_SIZE_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec6bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting vector dataset for training\n",
    "dataset=tf.data.Dataset.from_tensor_slices((inputs,outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c50d1",
   "metadata": {},
   "source": [
    "Batch Size and Buffer size is used to shuffle the dataset.\n",
    "<br>Cache is used to improve speed of training\n",
    "<br>prefetch  with experimental.AUTOTUNE also speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c52e968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "BUFFER_SIZE=20000\n",
    "\n",
    "dataset=dataset.cache()\n",
    "dataset=dataset.shuffle(BUFFER_SIZE).batch(BUFFER_SIZE)\n",
    "dataset=dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e55db",
   "metadata": {},
   "source": [
    "Positional encoding formulae:\n",
    "\n",
    "$PE_{(pos, 2i)} = \\sin(pos/10000^{2i/dmodel})$  - Even positions\n",
    "\n",
    "$PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/dmodel})$ - Odd Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9009d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "    def get_angles(self,pos,i, d_model): #pos:(seq_length,1) i: (1,d_model)\n",
    "        angles = i/np.power(10000.,(2*(i//2))/np.float32(d_model))\n",
    "        return pos * angles #(seq_length,d_model)\n",
    "    def call(self,inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2] # length of sequences\n",
    "        d_model = inputs.shape.as_list()[-1] # last dimension\n",
    "        angles=self.get_angles(np.arange(seq_length)[:,np.newaxis],\n",
    "                               np.arange(d_model)[np.newaxis,:],\n",
    "                               d_model)\n",
    "        angles[:,0::2]=np.sin(angles[:,0::2]) # Applied to Even positions\n",
    "        angles[:,1::2]=np.cos(angles[:,1::2]) # Applied to Odd positions\n",
    "        pos_encoding=angles[np.newaxis,...] # We have one more dimension (...) means it takes everything\n",
    "        return inputs+tf.cast(pos_encoding,tf.float32) # Making them tensors and adding to inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56090c86",
   "metadata": {},
   "source": [
    "$Attention(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af4989c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Dot Product Attention\n",
    "# Here the mask is look ahead mash which doesn't allow the decoder to see next words or \n",
    "# padding mask that masks zeros at end of each sentence\n",
    "def scaled_dotproduct_attention(quries,keys,values,mask): \n",
    "    product=tf.matmul(quries,keys,transpose_b=True) # matrix multiplication of Q ad K \n",
    "    keys_dim=tf.cast(tf.shape(keys)[-1],tf.float32) # old dimension of keys\n",
    "    scaled_product=product/tf.math.sqrt(keys_dim) # scaling by dividing by root of dimension of K\n",
    "     # Appling mask and multiplying by very low -ve number so after softmask it will be 0 and won;t have any impact\n",
    "    if mask is not None:\n",
    "        scaled_product +=(mask*-1e9)\n",
    "    attention=tf.matmul(tf.nn.softmax(scaled_product,axis=-1), values) # Applying Softmax and matrix multiplication with V\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abdf6a",
   "metadata": {},
   "source": [
    "### Multi-head attention sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0640fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multihead Attention\n",
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self,nb_proj): # nb_proj is number of projections wwe want to perform\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.nb_proj=nb_proj\n",
    "    def build(self,input_shape):\n",
    "        self.d_model=input_shape[-1]\n",
    "        # making sure d_model / nb_proj gives integers\n",
    "        assert self.d_model % self.nb_proj == 0 \n",
    "        \n",
    "        self.d_proj=self.d_model//self.nb_proj # Dimension of each projection\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.query_lin = layers.Dense(units=self.d_model) \n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "        \n",
    "    def split_proj(self,inputs,batch_size): # inputs: (batch_size, seq_length,d_model)\n",
    "        shape = (batch_size,\n",
    "                 -1, \n",
    "                 self.nb_proj, \n",
    "                 self.d_proj)\n",
    "        splitted_inputs = tf.reshape(inputs,shape=shape) # We have this shape (batch_size,seq_length,np_proj, d_proj)\n",
    "        # We use transpose to convert to this (batch_size, np_proj,seq_length,d_proj)\n",
    "        return tf.transpose(splitted_inputs, perm =[0,2,1,3]) \n",
    "        \n",
    "    def call(self, queries,keys,values,mask):\n",
    "        batch_size=tf.shape(queries)[0]\n",
    "        \n",
    "        queries=self.query_lin(queries)\n",
    "        keys=self.key_lin(keys)\n",
    "        values=self.value_lin(values)\n",
    "        \n",
    "        queries = self.split_proj(queries,batch_size)\n",
    "        keys = self.split_proj(keys,batch_size)\n",
    "        values = self.split_proj(values,batch_size)\n",
    "\n",
    "        attention = scaled_dotproduct_attention(queries,keys,values,mask) # Calling sclaed dot product for attention\n",
    "        attention = tf.transpose(attention, perm = [0,2,1,3])\n",
    "        \n",
    "        concat_attention= tf.reshape(attention,\n",
    "                                     shape=(batch_size,-1,self.d_model)) \n",
    "        \n",
    "        outputs = self.final_lin(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc91bbc",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b5116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self,FFN_units, nb_proj, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.d_model=input_shape[-1]\n",
    "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units,activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model,activation='relu')\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, mask, training):\n",
    "        attention = self.multi_head_attention(inputs,inputs,inputs,mask)\n",
    "        attention =self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention+inputs)\n",
    "        outputs=self.dense_1(attention)\n",
    "        outputs=self.dense_2(outputs)\n",
    "        outputs =self.dropout_2(outputs)\n",
    "        outputs = self.norm_2(outputs+attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62287e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "               nb_layers,\n",
    "               FFN_units,\n",
    "              nb_proj,\n",
    "              dropout,\n",
    "              vocab_size,\n",
    "              d_model,\n",
    "              name=\"encoder\"):\n",
    "        super(Encoder,self).__init__(name=name)\n",
    "        self.nb_layers=nb_layers\n",
    "        self.d_model=d_model\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.enc_layers = [EncoderLayer(FFN_units,\n",
    "                                        nb_proj,\n",
    "                                        dropout)\n",
    "                           for _ in range(nb_layers)]\n",
    "        \n",
    "    def call(self,inputs,mask,training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs,training)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8e1e0",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa37920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self,FFN_units, nb_proj, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.nb_proj = nb_proj\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.d_model=input_shape[-1]\n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units,activation='relu')\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        attention = self.multi_head_attention_1(inputs,\n",
    "                                              inputs,\n",
    "                                              inputs,\n",
    "                                              mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention +  inputs)\n",
    "        \n",
    "        attention_2 = self.multi_head_attention_2(attention,\n",
    "                                              enc_outputs,\n",
    "                                              enc_outputs,\n",
    "                                              mask_2)\n",
    "        attention_2 = self.dropout_2(attention_2,training)\n",
    "        attention_2 = self.norm_2(attention_2 +  attention)\n",
    "        \n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(outputs +  attention_2)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce58414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "               nb_layers,\n",
    "               FFN_units,\n",
    "              nb_proj,\n",
    "              dropout,\n",
    "              vocab_size,\n",
    "              d_model,\n",
    "              name='decoder'):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model=d_model\n",
    "        self.nb_layers = nb_layers\n",
    "        \n",
    "        self.embedding =  layers.Embedding(vocab_size,d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(FFN_units, nb_proj,dropout)\n",
    "                           for _ in range(nb_layers)]\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        outputs=self.embedding(inputs)\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs,training)\n",
    "        \n",
    "        for i in range(self.nb_layers):\n",
    "            outputs = self.dec_layers[i](outputs,\n",
    "                                         enc_outputs,\n",
    "                                         mask_1,\n",
    "                                         mask_2,\n",
    "                                         training)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a5f68",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe9eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,vocab_size_enc,\n",
    "              vocab_size_dec,\n",
    "              d_model,\n",
    "              nb_layers,\n",
    "              FFN_units,\n",
    "              nb_proj,\n",
    "              dropout,\n",
    "              name=\"transformer\"):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "        \n",
    "        self.encoder = Encoder(nb_layers,\n",
    "                              FFN_units,\n",
    "                              nb_proj,\n",
    "                              dropout,\n",
    "                              vocab_size_enc,\n",
    "                              d_model)\n",
    "        self.decoder = Decoder(nb_layers,\n",
    "                              FFN_units,\n",
    "                              nb_proj,\n",
    "                              dropout,\n",
    "                              vocab_size_dec,\n",
    "                              d_model)\n",
    "        \n",
    "        self.last_linear = layers.Dense(units=vocab_size_dec)\n",
    "        \n",
    "    def create_padding_mask(self, seq): # seq: (batch_size,seq_length)\n",
    "        mask = tf.cast(tf.math.equal(seq,0),tf.float32)\n",
    "        return mask[:,tf.newaxis,tf.newaxis,:]\n",
    "    \n",
    "    # While translating we do not need to know future words.\n",
    "    '''Creates a  square matrix of seq_len. if i>j matrix element is 1 else\n",
    "    matrix element is 0'''\n",
    "    def create_look_ahead_mask(self, seq):\n",
    "        seq_len = tf.shape(seq)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len,seq_len)),-1,0)\n",
    "        return look_ahead_mask\n",
    "    \n",
    "    def call(self, enc_inputs,dec_inputs, training):\n",
    "        enc_mask=self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1= tf.maximum(self.create_padding_mask(dec_inputs), \n",
    "                               self.create_look_ahead_mask(dec_inputs))\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        \n",
    "        enc_outputs = self.encoder(enc_inputs,enc_mask, training)\n",
    "        dec_outputs = self.decoder(dec_inputs,\n",
    "                                   enc_outputs,\n",
    "                                   dec_mask_1,\n",
    "                                   dec_mask_2,\n",
    "                                   training)\n",
    "        \n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc748e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Formula used for Look Ahead Mask\n",
    "print(1 - tf.linalg.band_part(tf.ones((5,5)),-1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be921bb2",
   "metadata": {},
   "source": [
    "# Application\n",
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0e0917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Hyper parameters\n",
    "D_MODEL=128 # 512 in All you need is Attention\n",
    "NB_LAYERS=6 # 6\n",
    "FFN_UNITS = 512 # 2048 in All you need is Attention\n",
    "NB_PROJ = 8 # 8\n",
    "DROUPOUT = 0.01 # 0.1 in All you need is Attention\n",
    "\n",
    "transformer = Transformer(vocab_size_enc = VOCAB_SIZE_QUESTIONS, # 1796\n",
    "                          vocab_size_dec = VOCAB_SIZE_QUERIES, # 2019\n",
    "                          d_model= D_MODEL,\n",
    "                          nb_layers=NB_LAYERS,\n",
    "                          FFN_units=FFN_UNITS,\n",
    "                          nb_proj=NB_PROJ,\n",
    "                          dropout=DROUPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54022de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction=\"none\")\n",
    "\n",
    "def loss_funstion(target, pred):\n",
    "    #To mask padding tokens when computing loss so we only use prediction of real words and not the 0s we added at end\n",
    "    mask=tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_=loss_object(target,pred)\n",
    "    \n",
    "    mask = tf.cast(mask,dtype=loss_.dtype)\n",
    "    loss_*=mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# Keeps track of losses during training\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "# Keeps track of training Accuracy\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0b436",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "$Irate = d^{(-0.5)}_{(model)} \\cdot min(step\\_num^{(-0.5)}, step\\_num \\cdot warmup\\_steps^{(-1.5)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d9645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create custom Learning Rate\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule,self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model,\n",
    "                               tf.float32)\n",
    "        self.warmup_steps=warmup_steps\n",
    "        \n",
    "    def __call__(self,step):\n",
    "        arg1=tf.math.rsqrt(step)\n",
    "        arg2=step*(self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model)*tf.math.minimum(arg1,arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65201511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Checkpoint Restored\n"
     ]
    }
   ],
   "source": [
    "# Using Custom LEarning rate in Adam Model\n",
    "learning_rate=CustomSchedule(D_MODEL)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate,\n",
    "                                   beta_1=0.9,\n",
    "                                   beta_2=0.98,\n",
    "                                   epsilon=1e-9)\n",
    "\n",
    "checkpoint_path =\"Checkpoints\"\n",
    "ckpt=tf.train.Checkpoint(transformer=transformer,\n",
    "                   optimizer=optimizer)\n",
    "# Keeping only the last 5 checkpoints. If there are more than 5, the older ones get deleted.\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Latest Checkpoint Restored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3b819",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "( Do not execute this unless you want to train the model again. Themodel has been trained already for 1500 epoch and provides an accuracy of 82 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08fe773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Batch 0 Loss 0.0035 Accuracy 0.8265\n",
      "Saving checkpoint for ecpoch 1 at Checkpoints\\ckpt-1501\n",
      "Time taken for 1 epoch 34.28913331031799 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=1\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Start of epoch {}\".format(epoch+1))\n",
    "    start=time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for(batch,(enc_inputs,targets)) in enumerate(dataset):\n",
    "        dec_inputs=targets[:,:-1]\n",
    "        dec_outputs_real = targets[:,1:]\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(enc_inputs,dec_inputs,True)\n",
    "            loss = loss_funstion(dec_outputs_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,transformer.trainable_variables ))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(dec_outputs_real,predictions)\n",
    "        \n",
    "        if batch%50==0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(epoch+1,\n",
    "                                                                          batch,\n",
    "                                                                          train_loss.result(),\n",
    "                                                                          train_accuracy.result()))\n",
    "                  \n",
    "        ckpt_save_path =ckpt_manager.save()\n",
    "        print(\"Saving checkpoint for ecpoch {} at {}\".format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "        print(\"Time taken for 1 epoch {} secs\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddf73d",
   "metadata": {},
   "source": [
    "# Vaidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c70ce78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[] #List to store predicted output\n",
    "\n",
    "#Cleaning the Validation Set Questions\n",
    "clean_questions_val=[]\n",
    "for question in X_valid['question']:\n",
    "    clean_questions_val.append(clean_text(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57f0a32",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5a789d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    inp_sentence = [VOCAB_SIZE_QUESTIONS-2] + tokenizer_questions.encode(inp_sentence) + [VOCAB_SIZE_QUESTIONS-1]\n",
    "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
    "        \n",
    "    output = tf.expand_dims([VOCAB_SIZE_QUERIES-2], axis=0)\n",
    "    \n",
    "    for _ in range(MAX_LENGTH):\n",
    "        predictions = transformer(enc_input, output, False) # 1, seq_length, VOCAB_SIZE_QUERIES\n",
    "        prediction = predictions[:, -1:, :]\n",
    "        \n",
    "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
    "        \n",
    "        if predicted_id == VOCAB_SIZE_QUERIES-1:\n",
    "            return tf.squeeze(output,axis=0)\n",
    "        \n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "def ChangeUndsc(predicted_sentence):\n",
    "    output=predicted_sentence.replace('\\&undsc','_')\n",
    "    return output\n",
    "\n",
    "def translate(sentence):\n",
    "    output = evaluate(sentence).numpy()\n",
    "    predicted_sentence = tokenizer_queries.decode(\n",
    "        [i for i in output if i < VOCAB_SIZE_QUERIES-2])\n",
    "    output = ChangeUndsc(predicted_sentence)\n",
    "    print(\"Input: {}\".format(sentence))\n",
    "    print(\"Predicted Translation : {}\".format(output))\n",
    "    \n",
    "    y_pred.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8dae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating Validation dataset (This will take a while)\n",
    "for question in clean_questions_val:    \n",
    "    translate(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7a602aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DF with X_valid, y_valid and y_pred\n",
    "y_valid = list(y_valid)\n",
    "zipped = list(zip(clean_questions_val, y_valid, y_pred))\n",
    "df_valid = pd.DataFrame(zipped, columns=['Questions','Query','Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "24e17274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['CorrectlyPredicted'] = np.where((df_valid['Query'] == df_valid['Predicted'])\n",
    "                     , df_valid['Query'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7e657b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25333333333333335\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of predicting the whole query sequence correctly\n",
    "accuracy = df_valid[\"CorrectlyPredicted\"].notna().sum(axis=0)/150\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf5bb3",
   "metadata": {},
   "source": [
    "Since we only used queries with a where condition and a Join. Lets check if all the predicted output has the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5349f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "''' Checking if the predicted query has a where condition and a Join clause'''\n",
    "def CountJoinAndWhere():\n",
    "    df1= pd.DataFrame(columns=['Query'])\n",
    "    df1=pd.concat([df1,df_valid.loc[df_valid['Predicted'].str.contains('WHERE', case=False)]],ignore_index=True, sort=False)\n",
    "    df2= pd.DataFrame(columns=['Query'])\n",
    "    for x in range(len(df1)):\n",
    "        if(df1.loc[x]['Query'].count('JOIN')==1):\n",
    "            df2=df2.append(df1.loc[x])\n",
    "    return len(df2)\n",
    "countJoinAndWhere = CountJoinAndWhere()\n",
    "\n",
    "# All the predicted queries have a Where Conditon and a single Join Clause\n",
    "print(countJoinAndWhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bfff63c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Table name always comes before 'AS' Keyword so\n",
    " we increment count by 1 if the table in the query\n",
    " is found in the predicted query. Count = 2 if both \n",
    " tables are predicted correctly. Count = 1 if one of the \n",
    " table is predicted correctly and Count = 0 when none of the tables are \n",
    " predicted correctly '''\n",
    "\n",
    "def CheckTables(query, predicted):\n",
    "    table=\"\"\n",
    "    count=0\n",
    "    t=query.split()\n",
    "    temp=t.copy()\n",
    "    for i in range(len(t)):\n",
    "        if t[i]=='AS':\n",
    "            table=t[i-1]\n",
    "            if table in predicted.split():\n",
    "                count+=1\n",
    "    return count\n",
    "cnt=[]\n",
    "for i in range(len(df_valid)):\n",
    "    cnt.append(CheckTables(df_valid['Query'].iloc[i],df_valid['Predicted'].iloc[i]))\n",
    "\n",
    "df_valid['TablesPredicted Correctly'] = cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2947bd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n"
     ]
    }
   ],
   "source": [
    "# accuracy of predicting tables correctly\n",
    "accuracy_tables=sum(cnt)/300\n",
    "print(accuracy_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "783b3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to measure the similarity between \n",
    "# two sentences using cosine similarity.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "  \n",
    "def CheckSimilarity(query, predicted):\n",
    "    X = query\n",
    "    Y = predicted\n",
    "  \n",
    "    # tokenization\n",
    "    X_list = word_tokenize(X) \n",
    "    Y_list = word_tokenize(Y)\n",
    "  \n",
    "    # sw contains the list of stopwords\n",
    "    sw = stopwords.words('english') \n",
    "    l1 =[];l2 =[]\n",
    "  \n",
    "    # remove stop words from the string\n",
    "    X_set = {w for w in X_list if not w in sw} \n",
    "    Y_set = {w for w in Y_list if not w in sw}\n",
    "  \n",
    "    # form a set containing keywords of both strings \n",
    "    rvector = X_set.union(Y_set) \n",
    "    for w in rvector:\n",
    "        if w in X_set: l1.append(1) # create a vector\n",
    "        else: l1.append(0)\n",
    "        if w in Y_set: l2.append(1)\n",
    "        else: l2.append(0)\n",
    "        c = 0\n",
    "  \n",
    "    # cosine formula \n",
    "    for i in range(len(rvector)):\n",
    "        c+= l1[i]*l2[i]\n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    #print(\"similarity: \", cosine)\n",
    "    return cosine\n",
    "sim=[]\n",
    "for i in range(len(df_valid)):\n",
    "    sim.append(CheckSimilarity(df_valid['Query'].iloc[i],df_valid['Predicted'].iloc[i]))\n",
    "df_valid['Similarity']=sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "dd651f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766533086086945\n"
     ]
    }
   ],
   "source": [
    "#Average similarity between Query and Predicted is 67 %\n",
    "average_sim=df_valid['Similarity'].mean()\n",
    "print(average_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "15f5eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Column name always has '.' eg:- 'T1.table_name'\n",
    "    We find wordswith '.' from the query and add it to a list.\n",
    "    Then increase a count if a word from the list appears in \n",
    "    the predicted query. Then we divide count b length of the list\n",
    "    to get the propotion of times column was predicted correctly\n",
    "'''\n",
    "def CheckColumnNames(query, predicted):\n",
    "    c=[]\n",
    "    count=0\n",
    "    out=0\n",
    "    for word in query.split():\n",
    "        if '.' in word:\n",
    "            c.append(word)\n",
    "    for word in predicted.split():\n",
    "        if '.' in word:\n",
    "            if word in c:\n",
    "                count+=1\n",
    "    if len(c) != 0:\n",
    "        out=count/len(c)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=[]\n",
    "for i in range(len(df_valid)):\n",
    "    ct.append(CheckColumnNames(df_valid['Query'].iloc[i],df_valid['Predicted'].iloc[i]))\n",
    "df_valid['Columns predicted Correctly']=ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c7fcc344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3802777777777777\n"
     ]
    }
   ],
   "source": [
    "# Average of Predicting columns correctly overall is 0.38\n",
    "average_cols = df_valid['Columns predicted Correctly'].mean()\n",
    "print(average_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c659a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Query</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>CorrectlyPredicted</th>\n",
       "      <th>TablesPredicted Correctly</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Columns predicted Correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHOW THE TIMES USED BY CLIMBERS TO CLIMB MOUNT...</td>\n",
       "      <td>SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...</td>\n",
       "      <td>SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...</td>\n",
       "      <td>SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHAT IS THE TEMPERATURE OF SHANGHAI CITY IN JA...</td>\n",
       "      <td>SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...</td>\n",
       "      <td>SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...</td>\n",
       "      <td>SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHAT ARE THE FIRST NAMES OF THE TEACHERS WHO T...</td>\n",
       "      <td>SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...</td>\n",
       "      <td>SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...</td>\n",
       "      <td>SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIND THE TOTAL AMOUNT OF PRODUCTS ORDERED BEFO...</td>\n",
       "      <td>SELECT SUM(T2.ORDER_QUANTITY) FROM CUSTOMER_OR...</td>\n",
       "      <td>SELECT T1.PRODUCT_NAME FROM PRODUCTS AS T1 JOI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.505722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHAT IS THE LAST NAME OF THE PROFESSOR WHOSE O...</td>\n",
       "      <td>SELECT T1.EMP_LNAME ,  T1.EMP_HIREDATE FROM EM...</td>\n",
       "      <td>SELECT T1.CATALOG_NAME ,  T1.TITLE FROM SHOP A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  SHOW THE TIMES USED BY CLIMBERS TO CLIMB MOUNT...   \n",
       "1  WHAT IS THE TEMPERATURE OF SHANGHAI CITY IN JA...   \n",
       "2  WHAT ARE THE FIRST NAMES OF THE TEACHERS WHO T...   \n",
       "3  FIND THE TOTAL AMOUNT OF PRODUCTS ORDERED BEFO...   \n",
       "4  WHAT IS THE LAST NAME OF THE PROFESSOR WHOSE O...   \n",
       "\n",
       "                                               Query  \\\n",
       "0  SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...   \n",
       "1  SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...   \n",
       "2  SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...   \n",
       "3  SELECT SUM(T2.ORDER_QUANTITY) FROM CUSTOMER_OR...   \n",
       "4  SELECT T1.EMP_LNAME ,  T1.EMP_HIREDATE FROM EM...   \n",
       "\n",
       "                                           Predicted  \\\n",
       "0  SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...   \n",
       "1  SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...   \n",
       "2  SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...   \n",
       "3  SELECT T1.PRODUCT_NAME FROM PRODUCTS AS T1 JOI...   \n",
       "4  SELECT T1.CATALOG_NAME ,  T1.TITLE FROM SHOP A...   \n",
       "\n",
       "                                  CorrectlyPredicted  \\\n",
       "0  SELECT T1.TIME FROM CLIMBER AS T1 JOIN MOUNTAI...   \n",
       "1  SELECT T2.JAN FROM CITY AS T1 JOIN TEMPERATURE...   \n",
       "2  SELECT DISTINCT T2.FIRSTNAME FROM LIST AS T1 J...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "   TablesPredicted Correctly  Similarity  Columns predicted Correctly  \n",
       "0                          2    1.000000                          1.0  \n",
       "1                          2    1.000000                          1.0  \n",
       "2                          2    1.000000                          1.0  \n",
       "3                          0    0.505722                          0.0  \n",
       "4                          0    0.564288                          0.0  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "77d3e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "df_valid.to_csv('ValidationSetDataFrame.csv',index=False, float_format='%.8g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f711fdd",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ffb142f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "#Cleaning the Questions\n",
    "clean_questions_test=[]\n",
    "for question in X_test['question']:\n",
    "    clean_questions_test.append(clean_text(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9fec032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating Testing dataset (This will take a while)\n",
    "for question in clean_questions_test:    \n",
    "    translate(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "24bb1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DF with X_test, y_test and y_test\n",
    "y_pred = list(y_pred)\n",
    "zipped = list(zip(clean_questions_test, y_test, y_pred))\n",
    "df_test = pd.DataFrame(zipped, columns=['Questions','Query','Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "267372c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Accuracy\n",
    "df_test['CorrectlyPredicted'] = np.where((df_test['Query'] == df_test['Predicted'])\n",
    "                     , df_test['Query'], np.nan)\n",
    "accuracy_test = df_test[\"CorrectlyPredicted\"].notna().sum(axis=0)/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bc3b5060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24666666666666667"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a51f6195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "countJoinAndWhere_test = CountJoinAndWhere()\n",
    "print(countJoinAndWhere_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a24061dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "# accuracy of predicting tables correctly\n",
    "cnt_test=[]\n",
    "for i in range(len(df_test)):\n",
    "    cnt_test.append(CheckTables(df_test['Query'].iloc[i],df_test['Predicted'].iloc[i]))\n",
    "\n",
    "df_test['TablesPredicted Correctly'] = cnt_test \n",
    "accuracy_tables_test=sum(cnt_test)/300\n",
    "print(accuracy_tables_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "75f589ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_test=[]\n",
    "for i in range(len(df_test)):\n",
    "    sim_test.append(CheckSimilarity(df_test['Query'].iloc[i],df_test['Predicted'].iloc[i]))\n",
    "df_test['Similarity']=sim_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6904f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905821815193827\n"
     ]
    }
   ],
   "source": [
    "#Average similarity between Query and Predicted is 67 %\n",
    "average_sim_test=df_test['Similarity'].mean()\n",
    "print(average_sim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "03f192e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_test=[]\n",
    "for i in range(len(df_test)):\n",
    "    ct_test.append(CheckColumnNames(df_test['Query'].iloc[i],df_test['Predicted'].iloc[i]))\n",
    "df_test['Columns predicted Correctly']=ct_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b00b5cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3876825396825397\n"
     ]
    }
   ],
   "source": [
    "# Average of Predicting columns correctly overall is 0.38\n",
    "average_cols_test = df_test['Columns predicted Correctly'].mean()\n",
    "print(average_cols_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "31aa03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating a Effeciveness Column for categorizing the effectiveness of the model\n",
    "Categorizing based on cosine similarity into very poor, poor, good, very good and excellent'''\n",
    "df_test['Effectiveness']=''\n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Similarity'].iloc[i]>=0 and df_test['Similarity'].iloc[i] <=0.2:\n",
    "        df_test['Effectiveness'].iloc[i]='Very Poor'\n",
    "    elif df_test['Similarity'].iloc[i]>0.2 and df_test['Similarity'].iloc[i] <=0.4:\n",
    "        df_test['Effectiveness'].iloc[i]='Poor'\n",
    "    elif df_test['Similarity'].iloc[i]>0.4 and df_test['Similarity'].iloc[i] <=0.6:\n",
    "        df_test['Effectiveness'].iloc[i]='Good'\n",
    "    elif df_test['Similarity'].iloc[i]>0.6 and df_test['Similarity'].iloc[i] <=0.8:\n",
    "        df_test['Effectiveness'].iloc[i]='Very Good'\n",
    "    else:\n",
    "         df_test['Effectiveness'].iloc[i]='Excellent'         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "903e0e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Query</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>CorrectlyPredicted</th>\n",
       "      <th>TablesPredicted Correctly</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Columns predicted Correctly</th>\n",
       "      <th>Effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNT THE NUMBER OF CREDIT CARDS THAT THE CUST...</td>\n",
       "      <td>SELECT COUNT(*) FROM CUSTOMERS_CARDS AS T1 JOI...</td>\n",
       "      <td>SELECT T2.CUSTOMER_FIRST_NAME ,  T2.CUSTOMER_L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701646</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHAT ARE THE LAST NAMES OF THE TEACHERS WHO TE...</td>\n",
       "      <td>SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...</td>\n",
       "      <td>SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...</td>\n",
       "      <td>SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIST THE IDS OF THE PROBLEMS FROM THE PRODUCT ...</td>\n",
       "      <td>SELECT T1.PROBLEM_ID FROM PROBLEMS AS T1 JOIN ...</td>\n",
       "      <td>SELECT T1.PROBLEM_ID FROM PROBLEMS AS T1 JOIN ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.653275</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Very Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHAT ARE THE TYPES OF VOCALS THAT THE BAND MEM...</td>\n",
       "      <td>SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...</td>\n",
       "      <td>SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...</td>\n",
       "      <td>SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHAT ARE THE DETAILS OF THE SHOPS THAT CAN BE ...</td>\n",
       "      <td>SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...</td>\n",
       "      <td>SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...</td>\n",
       "      <td>SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  COUNT THE NUMBER OF CREDIT CARDS THAT THE CUST...   \n",
       "1  WHAT ARE THE LAST NAMES OF THE TEACHERS WHO TE...   \n",
       "2  LIST THE IDS OF THE PROBLEMS FROM THE PRODUCT ...   \n",
       "3  WHAT ARE THE TYPES OF VOCALS THAT THE BAND MEM...   \n",
       "4  WHAT ARE THE DETAILS OF THE SHOPS THAT CAN BE ...   \n",
       "\n",
       "                                               Query  \\\n",
       "0  SELECT COUNT(*) FROM CUSTOMERS_CARDS AS T1 JOI...   \n",
       "1  SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...   \n",
       "2  SELECT T1.PROBLEM_ID FROM PROBLEMS AS T1 JOIN ...   \n",
       "3  SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...   \n",
       "4  SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...   \n",
       "\n",
       "                                           Predicted  \\\n",
       "0  SELECT T2.CUSTOMER_FIRST_NAME ,  T2.CUSTOMER_L...   \n",
       "1  SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...   \n",
       "2  SELECT T1.PROBLEM_ID FROM PROBLEMS AS T1 JOIN ...   \n",
       "3  SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...   \n",
       "4  SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...   \n",
       "\n",
       "                                  CorrectlyPredicted  \\\n",
       "0                                                NaN   \n",
       "1  SELECT T2.LASTNAME FROM LIST AS T1 JOIN TEACHE...   \n",
       "2                                                NaN   \n",
       "3  SELECT TYPE FROM VOCALS AS T1 JOIN BAND AS T2 ...   \n",
       "4  SELECT T1.SHOP_DETAILS FROM SHOPS AS T1 JOIN T...   \n",
       "\n",
       "   TablesPredicted Correctly  Similarity  Columns predicted Correctly  \\\n",
       "0                          1    0.701646                          0.8   \n",
       "1                          2    1.000000                          1.0   \n",
       "2                          1    0.653275                          0.2   \n",
       "3                          2    1.000000                          1.0   \n",
       "4                          2    1.000000                          1.0   \n",
       "\n",
       "  Effectiveness  \n",
       "0     Very Good  \n",
       "1     Excellent  \n",
       "2     Very Good  \n",
       "3     Excellent  \n",
       "4     Excellent  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "08d31fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "df_test.to_csv('TestSetDataFrame.csv',index=False, float_format='%.8g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "39d7d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "90244f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.catplot(x='Effectiveness', y='Similarity', kind=\"violin\", inner=None, data=df_test,height=5, aspect=1.5)\n",
    "g = sns.swarmplot(x='Effectiveness', y='Similarity', color=\"k\", size=4, data=df_test, ax=g.ax)\n",
    "fig = g.get_figure()\n",
    "fig.savefig('SimilarityVsEffectiveness.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955a3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
